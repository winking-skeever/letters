<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>paper - Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="tags-heading">
        
          <h1>paper</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
<div class="container" role="main">
    <div class="posts-list">
      
        
      

      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-lost-unsupervised-object-detection/">
      <h2 class="post-title">LOST - Localizing objects with self supervised transformers</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Apr 16, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Lost - Localizing objects with self supervised transformers and no labels The core idea is to be able to use the hidden info within transformers to localize objects (&ldquo;subjects&rdquo;) within input images (much like a YOLO model but without further training).
How does it work ?   First, we assume that there&rsquo;s at least one object to be found in the image.
  it relies on a selection of patches that are likely to belong to an object.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-lost-unsupervised-object-detection/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-transformer_interpretability_beyond_attention/">
      <h2 class="post-title">Transformer intrepretability beyond attention</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Apr 16, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Disadvantages of attention rollout and LRP Irrelevant tokens often get highlighted
The main challenge in assigning attributions based on attentions is that attentions are combining non-linearly from one layer to the next. The rollout method assumes that attentions are combined linearly and considers paths along the pairwise attention graph. We observe that this method often leads to an emphasis on irrelevant tokens since even average attention scores can be attenuated. The method also fails to distinguish between positive and negative contributions to the decision.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-transformer_interpretability_beyond_attention/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
      </div>
    
    <ul class="pager">
      
        <li class="previous">
          <a href="https://mayukhdeb.github.io/notes/tags/paper/page/3/">&larr; Newer</a>
        </li>
      
      
    </ul>
  
</div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2022
      </p>
  </div>
</footer></body>
</html>
