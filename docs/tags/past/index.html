<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>past - Writing</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/writing/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/writing/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/writing/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="tags-heading">
        
          <h1>past</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
<div class="container" role="main">
    <div class="posts-list">
      
        
      

      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/writing/post/2022-04-16-attention_flow/">
      <h2 class="post-title">Hello World</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Oct 24, 2021
  
    <br><i class="fa fa-folder-open"></i>
    
      <a href="https://mayukhdeb.github.io/writing//categories/past/">past</a>&nbsp;
    
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Attention Rollout for explaining transformers How is it better than just viewing raw attention maps ? Viewing raw attention maps as a way to explain transformers does not take into account the fact that we also have residual connections in the model. When we only use attention weights to approximate the flow of information in Transformers, we ignore the residual connections. But these connections play a significant role in tying corresponding positions in different layers.</p>
        <a href="https://mayukhdeb.github.io/writing/post/2022-04-16-attention_flow/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
      </div>
    
</div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/writing/about">Mayukh Deb</a>
        &copy;
        2022
      </p>
  </div>
</footer></body>
</html>
